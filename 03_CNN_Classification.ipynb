{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: https://www.kaggle.com/datasets/slothkong/10-monkey-species <br>\n",
    "Multi-class Classification <br>\n",
    "Custom CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn():\n",
    "    cnn = Sequential()\n",
    "    cnn.add(Input(shape=(400,300,3))) # (400,300)\n",
    "    cnn.add(Conv2D(filters=5,kernel_size=5,activation=\"relu\")) # (396,296)\n",
    "    cnn.add(MaxPooling2D()) # (198,148) # MaxPooling layer reduces the image size by half \n",
    "    cnn.add(Conv2D(filters=10,kernel_size=5,activation=\"relu\")) # (194,144,10)\n",
    "    cnn.add(MaxPooling2D()) # (97,72,10) # MaxPooling does not affect the number of channels\n",
    "    cnn.add(Conv2D(filters=20,kernel_size=5,activation=\"relu\")) # (93,68)\n",
    "    cnn.add(MaxPooling2D()) # (46,34)\n",
    "    cnn.add(Conv2D(filters=40,kernel_size=5,activation=\"relu\")) # (42,30)\n",
    "    cnn.add(MaxPooling2D()) # (21,15,40)\n",
    "    cnn.add(Conv2D(filters=80,kernel_size=5,activation=\"relu\")) # (17,11,80)\n",
    "    cnn.add(MaxPooling2D()) # (8,5,80)\n",
    "    cnn.add(Flatten()) # vector length = 8*5*80 = 3200\n",
    "    cnn.add(Dense(units=3200,activation=\"relu\"))\n",
    "    cnn.add(Dense(units=10,activation=\"softmax\")) # 10 units for 10 species (class) of monkeys\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = create_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 396, 296, 5)       380       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 198, 148, 5)       0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 194, 144, 10)      1260      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 97, 72, 10)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 93, 68, 20)        5020      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 46, 34, 20)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 42, 30, 40)        20040     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 21, 15, 40)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 17, 11, 80)        80080     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 8, 5, 80)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3200)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3200)              10243200  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                32010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10381990 (39.60 MB)\n",
      "Trainable params: 10381990 (39.60 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reason of using MaxPooling layer and our choice of filters number\n",
    "Size of image due to convolution does not decrease much. If we don't use MaxPooling layer then length of vector (size of image times number of filters) we get in Flatten layer will be very large. We will get very large number of feature. No. of parameters of Dense layer will be square of that large number. So, we will get very huge number of parameters in our Dense layers. This will make our model very slow to train. <br>\n",
    "So, we use MaxPooling layer so that image dimension get reduced to moderate value till Flatten layer. To compensate this reduction we are increasing the number of filters. matrix size is getting reduced but the depth is increasing due increase in number of filters."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1/255.0)\n",
    "# rescale = 1/255.0 => It will divide every pexel value with 255. \n",
    "# Due to this values get b/w 0 and 1 (max normalisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_list = os.listdir(\"03_Dataset/training/training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n0', 'n7', 'n9', 'n8', 'n6', 'n1', 'n4', 'n3', 'n2', 'n5']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories_list\n",
    "# order we are getting is random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Order of classes passed matters\n",
    "In case of binary class classification, <br>\n",
    "If we pass [\"Cat\",\"Dog\"] then cat is given label = 1 (model predict probability of cat) <br>\n",
    "Else if we pass [\"Dog\",\"Cat\"] then dog is given label = 1 (model predict probability of dog) <br> <br>\n",
    "In case of multi-class classification, <br>\n",
    "The class whose folder name is placed at index i will get encoded with label=i. <br>\n",
    "So, in probability vector, outputed by the model, probability of this class is filled at index i. <br> <br>\n",
    "\n",
    "Here, you can see that we have filled \"n9\" at index 2, so probality of an image belonging to class \"n9\" will be filled at index 2. <br>\n",
    "If ground truth of an image is class n9 then its ground truth y (label data) have 1 at index 3 and 0 at rest of the indices. <br> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1098 images in training directory\n",
      "There are 272 images in validation directory\n"
     ]
    }
   ],
   "source": [
    "total_training_images=0\n",
    "total_validation_images=0\n",
    "for folder_name in os.listdir(\"03_Dataset/training/training\"):\n",
    "    total_training_images += len(os.listdir(\"03_Dataset/training/training\"+\"/\"+folder_name))\n",
    "    total_validation_images+=len(os.listdir(\"03_Dataset/validation/validation/\"+folder_name))\n",
    "\n",
    "print(\"There are {} images in training directory\".format(total_training_images))\n",
    "print(\"There are {} images in validation directory\".format(total_validation_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1098 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "training_datagen = datagen.flow_from_directory(directory=\"03_Dataset/training/training\",\n",
    "                                               target_size=(400,300),\n",
    "                                               color_mode=\"rgb\",\n",
    "                                               classes=categories_list,\n",
    "                                               batch_size=18)\n",
    "# CNNs do not work on variable image sizes. We have to fix every image's size\n",
    "# You don't have to worry if your dataset has varying image sizes\n",
    "# Each image will be adjusted to the target_size we specify in this data generator\n",
    "\n",
    "# classes = list of folder names of each class\n",
    "# Directly we can pass like this: [\"n0\", \"n1\", ..... , \"n9\"]\n",
    "\n",
    "# class_mode - default is set to \"categprical\" which means multi-class\n",
    "# For binary classification, set it to \"binary\"\n",
    "\n",
    "# batch_size= should be a number which divides the datasize (training data size here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 272 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = datagen.flow_from_directory(directory=\"03_Dataset/validation/validation\",\n",
    "                                               target_size=(400,300),\n",
    "                                               color_mode=\"rgb\",\n",
    "                                               classes=categories_list,\n",
    "                                               batch_size=272)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.preprocessing.image.DirectoryIterator at 0x29426ab20>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mini_batch,Y_train_mini_batch = training_datagen.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.30980393, 0.34117648, 0.2509804 ],\n",
       "         [0.43921572, 0.48235297, 0.4156863 ],\n",
       "         [0.43137258, 0.454902  , 0.4156863 ],\n",
       "         ...,\n",
       "         [0.37647063, 0.454902  , 0.41960788],\n",
       "         [0.7960785 , 0.80392164, 0.7843138 ],\n",
       "         [0.8235295 , 0.8235295 , 0.8235295 ]],\n",
       "\n",
       "        [[0.2509804 , 0.29803923, 0.20392159],\n",
       "         [0.39607847, 0.4431373 , 0.3647059 ],\n",
       "         [0.44705886, 0.45882356, 0.4156863 ],\n",
       "         ...,\n",
       "         [0.34509805, 0.41176474, 0.3803922 ],\n",
       "         [0.6901961 , 0.6901961 , 0.68235296],\n",
       "         [0.8078432 , 0.80392164, 0.7960785 ]],\n",
       "\n",
       "        [[0.2392157 , 0.28627452, 0.19215688],\n",
       "         [0.38823533, 0.42352945, 0.34901962],\n",
       "         [0.36862746, 0.37647063, 0.33333334],\n",
       "         ...,\n",
       "         [0.34509805, 0.38823533, 0.37254903],\n",
       "         [0.6039216 , 0.59607846, 0.60784316],\n",
       "         [0.8117648 , 0.8078432 , 0.8000001 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.39607847, 0.34509805, 0.3137255 ],\n",
       "         [0.26666668, 0.22352943, 0.20784315],\n",
       "         [0.3019608 , 0.24705884, 0.24313727],\n",
       "         ...,\n",
       "         [0.03137255, 0.03137255, 0.03921569],\n",
       "         [0.04705883, 0.04705883, 0.05490196],\n",
       "         [0.04313726, 0.0509804 , 0.04705883]],\n",
       "\n",
       "        [[0.13333334, 0.10196079, 0.09411766],\n",
       "         [0.24705884, 0.21960786, 0.19607845],\n",
       "         [0.43921572, 0.41960788, 0.4039216 ],\n",
       "         ...,\n",
       "         [0.03921569, 0.03921569, 0.04705883],\n",
       "         [0.0509804 , 0.0509804 , 0.0509804 ],\n",
       "         [0.04313726, 0.0509804 , 0.04705883]],\n",
       "\n",
       "        [[0.16862746, 0.14509805, 0.14509805],\n",
       "         [0.3921569 , 0.37647063, 0.3647059 ],\n",
       "         [0.45882356, 0.4431373 , 0.43921572],\n",
       "         ...,\n",
       "         [0.03137255, 0.03137255, 0.03921569],\n",
       "         [0.0509804 , 0.0509804 , 0.05882353],\n",
       "         [0.03921569, 0.03921569, 0.03921569]]],\n",
       "\n",
       "\n",
       "       [[[0.64705884, 0.6431373 , 0.6627451 ],\n",
       "         [0.6862745 , 0.68235296, 0.7019608 ],\n",
       "         [0.7137255 , 0.70980394, 0.7294118 ],\n",
       "         ...,\n",
       "         [0.7137255 , 0.7607844 , 0.72156864],\n",
       "         [0.72156864, 0.7686275 , 0.72156864],\n",
       "         [0.7568628 , 0.8117648 , 0.75294125]],\n",
       "\n",
       "        [[0.67058825, 0.6666667 , 0.6862745 ],\n",
       "         [0.72156864, 0.7176471 , 0.7372549 ],\n",
       "         [0.7411765 , 0.7372549 , 0.7568628 ],\n",
       "         ...,\n",
       "         [0.74509805, 0.79215693, 0.75294125],\n",
       "         [0.7686275 , 0.81568635, 0.77647066],\n",
       "         [0.79215693, 0.8470589 , 0.7960785 ]],\n",
       "\n",
       "        [[0.7294118 , 0.7254902 , 0.74509805],\n",
       "         [0.77647066, 0.7725491 , 0.79215693],\n",
       "         [0.7803922 , 0.77647066, 0.7960785 ],\n",
       "         ...,\n",
       "         [0.78823537, 0.8235295 , 0.8117648 ],\n",
       "         [0.78823537, 0.8313726 , 0.8078432 ],\n",
       "         [0.8196079 , 0.86274517, 0.8313726 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.627451  , 0.5647059 , 0.5058824 ],\n",
       "         [0.86274517, 0.81568635, 0.7686275 ],\n",
       "         [0.9490197 , 0.91372555, 0.8941177 ],\n",
       "         ...,\n",
       "         [0.8941177 , 0.8196079 , 0.75294125],\n",
       "         [0.8941177 , 0.8078432 , 0.7254902 ],\n",
       "         [0.8941177 , 0.7960785 , 0.70980394]],\n",
       "\n",
       "        [[0.8196079 , 0.7843138 , 0.7176471 ],\n",
       "         [0.8941177 , 0.8470589 , 0.8000001 ],\n",
       "         [0.9843138 , 0.91372555, 0.8980393 ],\n",
       "         ...,\n",
       "         [0.91372555, 0.8313726 , 0.7568628 ],\n",
       "         [0.91372555, 0.81568635, 0.7372549 ],\n",
       "         [0.9058824 , 0.8000001 , 0.7176471 ]],\n",
       "\n",
       "        [[0.9921569 , 0.98823535, 0.9176471 ],\n",
       "         [0.8313726 , 0.7803922 , 0.74509805],\n",
       "         [0.7490196 , 0.6392157 , 0.627451  ],\n",
       "         ...,\n",
       "         [0.909804  , 0.82745105, 0.75294125],\n",
       "         [0.909804  , 0.80392164, 0.72156864],\n",
       "         [0.9058824 , 0.7843138 , 0.7019608 ]]],\n",
       "\n",
       "\n",
       "       [[[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [0.5764706 , 0.5176471 , 0.43529415],\n",
       "         [0.65882355, 0.6       , 0.5176471 ],\n",
       "         [0.5803922 , 0.52156866, 0.43921572]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [0.5764706 , 0.5176471 , 0.43529415],\n",
       "         [0.60784316, 0.54901963, 0.4666667 ],\n",
       "         [0.60784316, 0.54901963, 0.4666667 ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [0.6313726 , 0.57254905, 0.4901961 ],\n",
       "         [0.627451  , 0.5686275 , 0.48627454],\n",
       "         [0.6509804 , 0.5921569 , 0.50980395]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.11764707, 0.12156864, 0.13725491],\n",
       "         [0.1137255 , 0.11764707, 0.13333334],\n",
       "         [0.12156864, 0.1254902 , 0.14117648],\n",
       "         ...,\n",
       "         [0.20392159, 0.21568629, 0.2509804 ],\n",
       "         [0.21960786, 0.23137257, 0.26666668],\n",
       "         [0.22352943, 0.23529413, 0.27058825]],\n",
       "\n",
       "        [[0.12941177, 0.13333334, 0.14901961],\n",
       "         [0.12156864, 0.1254902 , 0.14117648],\n",
       "         [0.1254902 , 0.12941177, 0.14509805],\n",
       "         ...,\n",
       "         [0.20000002, 0.21176472, 0.24705884],\n",
       "         [0.21176472, 0.22352943, 0.25882354],\n",
       "         [0.20784315, 0.21960786, 0.25490198]],\n",
       "\n",
       "        [[0.13725491, 0.14117648, 0.15686275],\n",
       "         [0.12941177, 0.13333334, 0.14901961],\n",
       "         [0.1254902 , 0.12941177, 0.14509805],\n",
       "         ...,\n",
       "         [0.19607845, 0.20784315, 0.24313727],\n",
       "         [0.20784315, 0.21960786, 0.25490198],\n",
       "         [0.20784315, 0.21960786, 0.25490198]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.14901961, 0.16078432, 0.18823531],\n",
       "         [0.13725491, 0.14901961, 0.1764706 ],\n",
       "         [0.18039216, 0.19215688, 0.21960786],\n",
       "         ...,\n",
       "         [0.20784315, 0.20784315, 0.21568629],\n",
       "         [0.26666668, 0.26666668, 0.27450982],\n",
       "         [0.4431373 , 0.43137258, 0.41176474]],\n",
       "\n",
       "        [[0.15686275, 0.16862746, 0.19607845],\n",
       "         [0.14117648, 0.15294118, 0.18039216],\n",
       "         [0.21960786, 0.23137257, 0.25882354],\n",
       "         ...,\n",
       "         [0.2901961 , 0.29411766, 0.3019608 ],\n",
       "         [0.34117648, 0.34117648, 0.34117648],\n",
       "         [0.4901961 , 0.47450984, 0.43921572]],\n",
       "\n",
       "        [[0.14901961, 0.16470589, 0.1764706 ],\n",
       "         [0.15294118, 0.16470589, 0.20000002],\n",
       "         [0.28235295, 0.29803923, 0.29411766],\n",
       "         ...,\n",
       "         [0.2627451 , 0.2784314 , 0.27450982],\n",
       "         [0.25882354, 0.25882354, 0.2509804 ],\n",
       "         [0.454902  , 0.427451  , 0.38823533]]],\n",
       "\n",
       "\n",
       "       [[[0.8117648 , 0.86274517, 0.9294118 ],\n",
       "         [0.8196079 , 0.86274517, 0.9333334 ],\n",
       "         [0.81568635, 0.8588236 , 0.9294118 ],\n",
       "         ...,\n",
       "         [0.8705883 , 0.9215687 , 0.9960785 ],\n",
       "         [0.86274517, 0.91372555, 0.98823535],\n",
       "         [0.86274517, 0.91372555, 0.9803922 ]],\n",
       "\n",
       "        [[0.8117648 , 0.86274517, 0.9294118 ],\n",
       "         [0.8117648 , 0.86274517, 0.9294118 ],\n",
       "         [0.81568635, 0.8588236 , 0.9294118 ],\n",
       "         ...,\n",
       "         [0.86666673, 0.9176471 , 0.9921569 ],\n",
       "         [0.86666673, 0.9176471 , 0.9921569 ],\n",
       "         [0.86666673, 0.9176471 , 0.9843138 ]],\n",
       "\n",
       "        [[0.8117648 , 0.86274517, 0.9294118 ],\n",
       "         [0.8117648 , 0.86274517, 0.9294118 ],\n",
       "         [0.81568635, 0.8588236 , 0.9294118 ],\n",
       "         ...,\n",
       "         [0.86666673, 0.9176471 , 0.9921569 ],\n",
       "         [0.86666673, 0.9176471 , 0.9921569 ],\n",
       "         [0.86666673, 0.9176471 , 0.9843138 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.6117647 , 0.5647059 , 0.5019608 ],\n",
       "         [0.6117647 , 0.5647059 , 0.5019608 ],\n",
       "         [0.60784316, 0.56078434, 0.5058824 ],\n",
       "         ...,\n",
       "         [0.21176472, 0.19607845, 0.16078432],\n",
       "         [0.22352943, 0.20784315, 0.17254902],\n",
       "         [0.22352943, 0.18823531, 0.15294118]],\n",
       "\n",
       "        [[0.6117647 , 0.5647059 , 0.5019608 ],\n",
       "         [0.6117647 , 0.5647059 , 0.5019608 ],\n",
       "         [0.60784316, 0.56078434, 0.5058824 ],\n",
       "         ...,\n",
       "         [0.20392159, 0.16862746, 0.13333334],\n",
       "         [0.21568629, 0.20000002, 0.16470589],\n",
       "         [0.20392159, 0.1764706 , 0.13725491]],\n",
       "\n",
       "        [[0.61960787, 0.57254905, 0.50980395],\n",
       "         [0.62352943, 0.5764706 , 0.5137255 ],\n",
       "         [0.6156863 , 0.5686275 , 0.5058824 ],\n",
       "         ...,\n",
       "         [0.23137257, 0.19215688, 0.15686275],\n",
       "         [0.18823531, 0.16862746, 0.14509805],\n",
       "         [0.20784315, 0.18039216, 0.14901961]]],\n",
       "\n",
       "\n",
       "       [[[0.21568629, 0.33333334, 0.3254902 ],\n",
       "         [0.20784315, 0.32156864, 0.30588236],\n",
       "         [0.20000002, 0.3137255 , 0.29803923],\n",
       "         ...,\n",
       "         [0.25490198, 0.3372549 , 0.18431373],\n",
       "         [0.2784314 , 0.36078432, 0.20784315],\n",
       "         [0.32941177, 0.41176474, 0.25882354]],\n",
       "\n",
       "        [[0.21568629, 0.34117648, 0.29803923],\n",
       "         [0.20784315, 0.3254902 , 0.28627452],\n",
       "         [0.20000002, 0.31764707, 0.2784314 ],\n",
       "         ...,\n",
       "         [0.23529413, 0.33333334, 0.21568629],\n",
       "         [0.25490198, 0.3529412 , 0.227451  ],\n",
       "         [0.29411766, 0.3921569 , 0.26666668]],\n",
       "\n",
       "        [[0.20784315, 0.3372549 , 0.29411766],\n",
       "         [0.20784315, 0.3254902 , 0.28627452],\n",
       "         [0.21176472, 0.31764707, 0.28235295],\n",
       "         ...,\n",
       "         [0.19607845, 0.30980393, 0.23137257],\n",
       "         [0.20784315, 0.32156864, 0.24313727],\n",
       "         [0.23137257, 0.34509805, 0.26666668]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.3372549 , 0.33333334, 0.3137255 ],\n",
       "         [0.39607847, 0.40000004, 0.37647063],\n",
       "         [0.36862746, 0.38823533, 0.36078432],\n",
       "         ...,\n",
       "         [0.27450982, 0.3372549 , 0.3254902 ],\n",
       "         [0.27058825, 0.33333334, 0.32156864],\n",
       "         [0.25490198, 0.32156864, 0.29803923]],\n",
       "\n",
       "        [[0.38823533, 0.4156863 , 0.38431376],\n",
       "         [0.32941177, 0.36862746, 0.3372549 ],\n",
       "         [0.29803923, 0.34117648, 0.30980393],\n",
       "         ...,\n",
       "         [0.21568629, 0.2784314 , 0.26666668],\n",
       "         [0.19607845, 0.25882354, 0.24705884],\n",
       "         [0.14117648, 0.20392159, 0.19215688]],\n",
       "\n",
       "        [[0.28627452, 0.3372549 , 0.29803923],\n",
       "         [0.2901961 , 0.3529412 , 0.30980393],\n",
       "         [0.30980393, 0.3803922 , 0.33333334],\n",
       "         ...,\n",
       "         [0.09411766, 0.15686275, 0.14509805],\n",
       "         [0.08235294, 0.14509805, 0.13333334],\n",
       "         [0.0627451 , 0.1254902 , 0.1137255 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mini_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_mini_batch\n",
    "# You can see the one hot encoding here\n",
    "# These are ground truth vectors\n",
    "# Values inside vectors representing probabilities\n",
    "# 18 vectors (for 18 images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(loss=\"categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\",tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "# keeping default optimiser (rmsprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 14:45:26.556357: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - ETA: 0s - loss: 2.3642 - accuracy: 0.1503 - precision: 0.2273 - recall: 0.0091"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 14:46:05.167334: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 44s 708ms/step - loss: 2.3642 - accuracy: 0.1503 - precision: 0.2273 - recall: 0.0091 - val_loss: 2.1371 - val_accuracy: 0.2022 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/15\n",
      "61/61 [==============================] - 40s 657ms/step - loss: 1.9909 - accuracy: 0.2550 - precision: 0.3814 - recall: 0.0410 - val_loss: 1.9007 - val_accuracy: 0.2941 - val_precision: 0.4000 - val_recall: 0.0147\n",
      "Epoch 3/15\n",
      "61/61 [==============================] - 42s 683ms/step - loss: 1.8538 - accuracy: 0.3142 - precision: 0.4417 - recall: 0.0656 - val_loss: 1.8075 - val_accuracy: 0.3235 - val_precision: 0.4583 - val_recall: 0.0404\n",
      "Epoch 4/15\n",
      "61/61 [==============================] - 43s 698ms/step - loss: 1.6818 - accuracy: 0.3780 - precision: 0.5840 - recall: 0.1393 - val_loss: 2.1634 - val_accuracy: 0.2574 - val_precision: 0.4362 - val_recall: 0.1507\n",
      "Epoch 5/15\n",
      "61/61 [==============================] - 43s 710ms/step - loss: 1.4585 - accuracy: 0.4636 - precision: 0.6601 - recall: 0.2459 - val_loss: 1.5946 - val_accuracy: 0.4118 - val_precision: 0.6552 - val_recall: 0.1397\n",
      "Epoch 6/15\n",
      "61/61 [==============================] - 45s 728ms/step - loss: 1.2315 - accuracy: 0.5665 - precision: 0.7540 - recall: 0.3852 - val_loss: 1.6849 - val_accuracy: 0.4338 - val_precision: 0.5694 - val_recall: 0.3015\n",
      "Epoch 7/15\n",
      "61/61 [==============================] - 44s 725ms/step - loss: 0.9282 - accuracy: 0.6621 - precision: 0.7948 - recall: 0.5537 - val_loss: 2.0594 - val_accuracy: 0.4559 - val_precision: 0.5046 - val_recall: 0.4007\n",
      "Epoch 8/15\n",
      "61/61 [==============================] - 45s 740ms/step - loss: 0.7518 - accuracy: 0.7404 - precision: 0.8061 - recall: 0.6475 - val_loss: 1.6758 - val_accuracy: 0.4779 - val_precision: 0.5852 - val_recall: 0.3787\n",
      "Epoch 9/15\n",
      "61/61 [==============================] - 45s 733ms/step - loss: 0.5147 - accuracy: 0.8206 - precision: 0.8715 - recall: 0.7596 - val_loss: 1.6641 - val_accuracy: 0.5551 - val_precision: 0.6520 - val_recall: 0.4890\n",
      "Epoch 10/15\n",
      "61/61 [==============================] - 45s 736ms/step - loss: 0.3565 - accuracy: 0.8889 - precision: 0.9193 - recall: 0.8607 - val_loss: 1.9798 - val_accuracy: 0.5441 - val_precision: 0.5894 - val_recall: 0.5331\n",
      "Epoch 11/15\n",
      "61/61 [==============================] - 45s 736ms/step - loss: 0.2781 - accuracy: 0.9317 - precision: 0.9411 - recall: 0.9162 - val_loss: 2.7814 - val_accuracy: 0.5956 - val_precision: 0.6056 - val_recall: 0.5588\n",
      "Epoch 12/15\n",
      "61/61 [==============================] - 46s 747ms/step - loss: 0.2518 - accuracy: 0.9299 - precision: 0.9361 - recall: 0.9199 - val_loss: 2.8928 - val_accuracy: 0.5294 - val_precision: 0.5364 - val_recall: 0.5147\n",
      "Epoch 13/15\n",
      "61/61 [==============================] - 46s 744ms/step - loss: 0.1598 - accuracy: 0.9627 - precision: 0.9679 - recall: 0.9599 - val_loss: 2.9708 - val_accuracy: 0.5662 - val_precision: 0.5775 - val_recall: 0.5478\n",
      "Epoch 14/15\n",
      "61/61 [==============================] - 49s 800ms/step - loss: 0.2388 - accuracy: 0.9563 - precision: 0.9570 - recall: 0.9526 - val_loss: 3.6196 - val_accuracy: 0.5110 - val_precision: 0.5375 - val_recall: 0.5000\n",
      "Epoch 15/15\n",
      "61/61 [==============================] - 48s 776ms/step - loss: 0.1062 - accuracy: 0.9699 - precision: 0.9707 - recall: 0.9672 - val_loss: 3.1587 - val_accuracy: 0.5551 - val_precision: 0.5843 - val_recall: 0.5478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29ba46d00>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(training_datagen,epochs=15,validation_data=validation_datagen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlintern",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
